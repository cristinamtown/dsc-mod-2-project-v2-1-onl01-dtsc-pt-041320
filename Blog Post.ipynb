{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Look into Freaky Franchise's Rotten Tomato Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podcasts are all the rage, especially in these weird times where many people have more free time than they did in the past. Today we are going to look at some gathered data from one particular podcast, Freaky Franchise where they \"unmask horror movies based on quantity over quality.\" I strongly suggest checking [Freaky Franchise](http://freakyfranchise.com/about) out if you are into horror movies.\n",
    "\n",
    "The first part of the episode the two hosts have a friendly competition where they guess the Rotten Tomato scores of the movies they are discussing, the loser having to sum the movie up in under a minute. In this post, we are going to look data surrounding this competition to see if we can predict which host will \"win\" the competition on any particular episode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we need to load in the data set and see what we are working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ff_data = pd.read_csv('Freaky_Franchise_data.csv')\n",
    "ff_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the data type of the columns and where we have null values\n",
    "ff_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this summery we can see a few things we will have to do to the DataFrame before we start using it to create statistical information.\n",
    "- First see that we can reset the index.\n",
    "- It seems like there is a second table on the bottom that we should remove before continuing\n",
    "- We can see that Cordie, Theo, the Difference in scores, and the RT scores are listed as objects while we will need them as floats or integers\n",
    "- In the same vein of above, we may want to convert Date Aired to DateTime.\n",
    "- We also see that there are some null values that we will have to deal with\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrubbing the data for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we are going to drop the extra table on the bottom. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the rows without an index (episode number) by telling pandas to just keep rows that\n",
    "# the episode number is not empty.\n",
    "ff_data = ff_data[ff_data['#'].notna()]\n",
    "ff_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we can set the index to the episode number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_data.set_index(\"#\", inplace=True)\n",
    "ff_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at the null values and decide what to do with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 of these columns have the same amount of null values. This could be a coincidence or the null values could be in the same row. We should look deeper into that since it could help us decide how we deal with the null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we are going to just look at rows that have null values\n",
    "ff_data[ff_data.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This produced more rows than we wanted. We want to see if the 12 in are the same\n",
    "# To check this we are going to create a new df without notes\n",
    "no_notes = ff_data.copy()\n",
    "no_notes.drop(labels='Notes', axis=1, inplace=True)\n",
    "no_notes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the same code again with no_notes to see all rows with null values\n",
    "no_notes[no_notes.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that like we suspected, the 12 null values all fall on the same rows. These episodes are mostly retrospectives and specials which we can guess (and I can confirm from listening to them) did not include the competition. Since the main thing we are looking at in this blog is the Rotten Tomato competition, we can safely drop these rows without loss of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same method we used to remove the extra table\n",
    "# Since the null values fall across the row, we just need to choose one column\n",
    "ff_data = ff_data[ff_data['Cordie'].notna()]\n",
    "ff_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at ff_data.info() again to check it worked\n",
    "ff_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have the data we will be working with, we need to convert it into a format we can work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a for loop we will convert all into float \n",
    "\n",
    "# First, create a list of the column names that we need to convert\n",
    "columns = ['Cordie', 'Theo', 'Difference in scores', 'RT Score']\n",
    "\n",
    "# Use a for loop to loop through columns to convert any columns that can be into floats\n",
    "for x in columns:\n",
    "    ff_data[x] = pd.to_numeric(ff_data[x], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that 'Theo', 'Difference in scores', and 'RT Score' have one less non-null object than before. That mean most likely there was a non-number filler which we converted to a null value when we coerced the errors. Seeing that, we will need to check for null values again and decide what to do with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking again for nulls using the same method as above\n",
    "no_notes = ff_data.copy()\n",
    "no_notes.drop(labels='Notes', axis=1, inplace=True)\n",
    "no_notes[no_notes.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there is one episode where Theo's guess is not listed and thus the difference is not listed and another episode where no Rotten Tomato Score is listed. Both of these episodes have winners so we shouldn't get drop them right out. Since it is just three null values, we are going replace the null values with probable answers using the other data we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since Cordie won the Sleepaway Camp IV with a guess of zero and simple search, I\n",
    "# found that the movie does not have a RT score so we will replace the null with a 0\n",
    "ff_data['RT Score'] = ff_data['RT Score'].fillna(0)\n",
    "\n",
    "# For Jason Lives, we know Theo wins so we will fill it with with the RT Score\n",
    "# Then fill difference with the difference between it and Cordie's guess\n",
    "ff_data['Theo'] = ff_data['Theo'].fillna(ff_data['RT Score'])\n",
    "ff_data['Difference in scores'] = ff_data['Difference in scores'].fillna(\n",
    "                                   abs(ff_data['Cordie'] - ff_data['Theo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls once again\n",
    "ff_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One last thing we will do before we start running test and models is create boolean columns of who went first and who won using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_data.columns = ff_data.columns.str.replace(' ', '_')\n",
    "ff_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are just going to keep the columns with data that will affect the model\n",
    "feats = ['Cordie','Theo','Difference_in_scores','RT_Score','Goes_First', 'Winner']\n",
    "ff_data = ff_data[feats]\n",
    "ff_data = pd.get_dummies(ff_data, drop_first=True)\n",
    "ff_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import six\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_data.hist(figsize = (20,18));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['Cordie','Theo','Difference_in_scores','RT_Score','Goes_First_Theo']\n",
    "corr = ff_data[feats].corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "sns.heatmap(corr, center=0, annot=True)\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot('Goes_First_Theo','Winner_Theo', \n",
    "              data=ff_data, kind='reg').annotate(stats.pearsonr)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot('Difference_in_scores','Winner_Theo', \n",
    "              data=ff_data, kind='reg').annotate(stats.pearsonr)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot('Difference_in_scores','Winner_Theo', \n",
    "              data=ff_data, kind='reg').annotate(stats.pearsonr)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally we can model the data and see what relationships we have between winning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the problem\n",
    "outcome = 'Winner_Theo'\n",
    "x_cols = list(ff_data.columns)\n",
    "x_cols.remove(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some brief preprocessing\n",
    "ff_data.columns = [col.replace(' ', '_') for col in ff_data.columns]\n",
    "for col in x_cols:\n",
    "    ff_data[col] = (ff_data[col] - ff_data[col].mean())/ff_data[col].std()\n",
    "ff_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the actual model\n",
    "predictors = '+'.join(x_cols)\n",
    "formula = outcome + '~' + predictors\n",
    "model = ols(formula=formula, data=ff_data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
